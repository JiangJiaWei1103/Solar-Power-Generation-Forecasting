# XGB model hyperparameters
model_params:
    # General
    booster: gbtree
    verbosity: 0
    n_jobs: -1
    # Tree booster
    n_estimators: 10000
    max_depth: 8
#     max_leaves: 0
#     max_bin: 256
#     grow_policy: depthwise
    learning_rate: 0.02  # https://www.quora.com/What-is-the-learning-rate-of-XGBoost
    tree_method: auto
    min_child_weight: 4.006813189196784
    subsample: 0.5391119972351586
    colsample_bytree: 0.984888996192305

    reg_alpha: 1.221644163794176
    reg_lambda: 5.720612822110147
#     num_parallel_tree: 1
#     monotone_constraints
#     interaction_constraint
    importance_type: gain
#     predictor: auto
    # Learning task
    objective: 'reg:squarederror'
    random_state: 42

fit_params:
    eval_metric: rmse
    early_stopping_rounds: 500
    verbose: True
